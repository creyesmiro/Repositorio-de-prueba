{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia 2de Artificial Neural Network",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/creyesmiro/Repositorio-de-prueba/blob/main/Modelo%20de%20Regresion%20-%20Predecir%20la%20producci%C3%B3n%20de%20energ%C3%ADa%20el%C3%A9ctrica%20de%20una%20central%20de%20ciclo%20combinado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cbb7fRy-eyr"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sNDnxE2-pwE"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxChR1Rk-umf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBTqR3nacj0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "abc147ae-5ecd-40fe-808b-cfb5e4728cf7"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG3FQEch-yuA"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4zq8Mza_D9O"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9CV13Co_HHM"
      },
      "source": [
        "# Abrimos la base de datos que previamente debe ser subida\n",
        "dataset = pd.read_excel('Folds5x2_pp.xlsx')\n",
        "\n",
        "#Separar variables dependientes e independientes\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC6omXel_Up0"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5edeb2r_agx"
      },
      "source": [
        "# Función seleccionador de modelos para compararlos y procesar datos desde una segunda biblioteca\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Recomendable 20 o 25 por ciento, numero de observaciones\n",
        "# random_state para evitar diferentes divisiones del conjunto de entrenamiento y del conjunto de prueba.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mSLlAT9_eyI"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsBULd_f_wLY"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6Hd97Ls__Nz"
      },
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iitAFJS_ABUn"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksO_Vv40AHix"
      },
      "source": [
        "# Units: número de neuronas ocultas\n",
        "# relu: Rectify activation function. Romperá la linealidad de las operaciones que ocurren entre la capa de entrada y la primera capa oculta\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lb4kK_wAKbs"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2357OqEAQOQ"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwMOmKb3AdBY"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFATpzsUAkLL"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq7e4fF6A1yy"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDeylAs2An25"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pesgbWlCAtB4"
      },
      "source": [
        "# Optimizar. Para aplicar stochastic gradient descent, denotado Adam. El optimizador actualizará todos los pesos dentro de esta nueva red con el fin de reducir esta carga.\n",
        "ann.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjVuiybYOo7r"
      },
      "source": [
        "### Training the ANN model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_vV-tiiA5zn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d9d0a51-56c4-4ace-cfd1-20fc41d9ee09"
      },
      "source": [
        "# Para entrenar usar método fit.\n",
        "# Para asegurarse de que se converge al reducir la pérdida se quiere empezar con el 100\n",
        "# Batch, conjunto de caracteristicas de la matriz para ser optimizadas a la vez.\n",
        "history=ann.fit(X_train, y_train, batch_size = 32, epochs = 100, validation_data=(X_val, y_val))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 746273.2500 - accuracy: 0.0000e+00 - val_loss: 407469.8438 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 292283.8125 - accuracy: 0.0000e+00 - val_loss: 227058.0938 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 210957.1250 - accuracy: 0.0000e+00 - val_loss: 206300.5156 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 206224.1250 - accuracy: 0.0000e+00 - val_loss: 206156.7031 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 206080.2500 - accuracy: 0.0000e+00 - val_loss: 206011.8594 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 205932.6250 - accuracy: 0.0000e+00 - val_loss: 205861.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 205779.8125 - accuracy: 0.0000e+00 - val_loss: 205705.9219 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 205622.9531 - accuracy: 0.0000e+00 - val_loss: 205547.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 205462.6406 - accuracy: 0.0000e+00 - val_loss: 205385.6562 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 205299.8750 - accuracy: 0.0000e+00 - val_loss: 205221.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "192/192 [==============================] - 1s 4ms/step - loss: 205135.1719 - accuracy: 0.0000e+00 - val_loss: 205056.1094 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 204968.8906 - accuracy: 0.0000e+00 - val_loss: 204889.1094 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 204801.3438 - accuracy: 0.0000e+00 - val_loss: 204720.9688 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 204632.7188 - accuracy: 0.0000e+00 - val_loss: 204551.9062 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 204463.4688 - accuracy: 0.0000e+00 - val_loss: 204382.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 204293.5625 - accuracy: 0.0000e+00 - val_loss: 204212.0469 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 204122.9844 - accuracy: 0.0000e+00 - val_loss: 204041.4062 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 203952.2969 - accuracy: 0.0000e+00 - val_loss: 203870.4531 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 203781.1875 - accuracy: 0.0000e+00 - val_loss: 203699.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 203609.7500 - accuracy: 0.0000e+00 - val_loss: 203527.7344 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 203438.2969 - accuracy: 0.0000e+00 - val_loss: 203356.1562 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 203266.6406 - accuracy: 0.0000e+00 - val_loss: 203184.4062 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 203094.8438 - accuracy: 0.0000e+00 - val_loss: 203012.5312 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 202922.9219 - accuracy: 0.0000e+00 - val_loss: 202840.6406 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 202751.0625 - accuracy: 0.0000e+00 - val_loss: 202668.7656 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 202579.1875 - accuracy: 0.0000e+00 - val_loss: 202496.9062 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 202407.2812 - accuracy: 0.0000e+00 - val_loss: 202324.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 202235.3438 - accuracy: 0.0000e+00 - val_loss: 202153.0312 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 202063.4375 - accuracy: 0.0000e+00 - val_loss: 201981.1562 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 201891.5312 - accuracy: 0.0000e+00 - val_loss: 201809.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 201719.8125 - accuracy: 0.0000e+00 - val_loss: 201637.5312 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 201547.9531 - accuracy: 0.0000e+00 - val_loss: 201465.7031 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 201376.2344 - accuracy: 0.0000e+00 - val_loss: 201294.0469 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 201204.5469 - accuracy: 0.0000e+00 - val_loss: 201122.3594 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 201032.9531 - accuracy: 0.0000e+00 - val_loss: 200950.7656 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 200861.4531 - accuracy: 0.0000e+00 - val_loss: 200779.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 200689.9531 - accuracy: 0.0000e+00 - val_loss: 200607.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 200518.5156 - accuracy: 0.0000e+00 - val_loss: 200436.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 200347.1562 - accuracy: 0.0000e+00 - val_loss: 200265.0469 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 200175.8438 - accuracy: 0.0000e+00 - val_loss: 200093.7656 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 200004.5000 - accuracy: 0.0000e+00 - val_loss: 199922.6094 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 199833.4062 - accuracy: 0.0000e+00 - val_loss: 199751.4219 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 199662.2500 - accuracy: 0.0000e+00 - val_loss: 199580.3594 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 199491.3125 - accuracy: 0.0000e+00 - val_loss: 199409.3906 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 199320.2969 - accuracy: 0.0000e+00 - val_loss: 199238.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 199149.4375 - accuracy: 0.0000e+00 - val_loss: 199067.6094 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 198978.5625 - accuracy: 0.0000e+00 - val_loss: 198896.7344 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 198807.8594 - accuracy: 0.0000e+00 - val_loss: 198726.0781 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 198637.1875 - accuracy: 0.0000e+00 - val_loss: 198555.4844 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 198466.6250 - accuracy: 0.0000e+00 - val_loss: 198384.8906 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 198296.0625 - accuracy: 0.0000e+00 - val_loss: 198214.3906 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 198125.6094 - accuracy: 0.0000e+00 - val_loss: 198044.0312 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 197955.2031 - accuracy: 0.0000e+00 - val_loss: 197873.6562 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 197784.9219 - accuracy: 0.0000e+00 - val_loss: 197703.4844 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 197614.7188 - accuracy: 0.0000e+00 - val_loss: 197533.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 197444.4219 - accuracy: 0.0000e+00 - val_loss: 197363.0781 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 197274.4844 - accuracy: 0.0000e+00 - val_loss: 197193.0312 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 197104.4531 - accuracy: 0.0000e+00 - val_loss: 197023.0312 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 196934.4688 - accuracy: 0.0000e+00 - val_loss: 196853.1562 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 196764.7188 - accuracy: 0.0000e+00 - val_loss: 196683.3281 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 196594.9062 - accuracy: 0.0000e+00 - val_loss: 196513.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 196425.2031 - accuracy: 0.0000e+00 - val_loss: 196343.9531 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 196255.5625 - accuracy: 0.0000e+00 - val_loss: 196174.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 196085.9375 - accuracy: 0.0000e+00 - val_loss: 196004.7812 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 195916.4844 - accuracy: 0.0000e+00 - val_loss: 195835.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 195746.9688 - accuracy: 0.0000e+00 - val_loss: 195665.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 195577.6875 - accuracy: 0.0000e+00 - val_loss: 195496.5469 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 195408.4062 - accuracy: 0.0000e+00 - val_loss: 195327.3594 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 195239.2188 - accuracy: 0.0000e+00 - val_loss: 195158.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 195070.0938 - accuracy: 0.0000e+00 - val_loss: 194989.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 194901.0000 - accuracy: 0.0000e+00 - val_loss: 194820.0312 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 194732.0000 - accuracy: 0.0000e+00 - val_loss: 194651.1094 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 194563.0781 - accuracy: 0.0000e+00 - val_loss: 194482.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 194394.2188 - accuracy: 0.0000e+00 - val_loss: 194313.4219 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 194225.5625 - accuracy: 0.0000e+00 - val_loss: 194144.7344 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 194056.8281 - accuracy: 0.0000e+00 - val_loss: 193976.0938 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 193888.2188 - accuracy: 0.0000e+00 - val_loss: 193807.4844 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 193719.6562 - accuracy: 0.0000e+00 - val_loss: 193638.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 193551.2344 - accuracy: 0.0000e+00 - val_loss: 193470.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 193382.8438 - accuracy: 0.0000e+00 - val_loss: 193302.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "192/192 [==============================] - 1s 4ms/step - loss: 193214.5000 - accuracy: 0.0000e+00 - val_loss: 193133.8594 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "192/192 [==============================] - 1s 5ms/step - loss: 193046.2656 - accuracy: 0.0000e+00 - val_loss: 192965.6719 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 192878.0781 - accuracy: 0.0000e+00 - val_loss: 192797.5469 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 192710.0312 - accuracy: 0.0000e+00 - val_loss: 192629.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 192542.0469 - accuracy: 0.0000e+00 - val_loss: 192461.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 192374.0938 - accuracy: 0.0000e+00 - val_loss: 192293.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 192206.2031 - accuracy: 0.0000e+00 - val_loss: 192125.7812 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 192038.4062 - accuracy: 0.0000e+00 - val_loss: 191957.9531 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 191870.6250 - accuracy: 0.0000e+00 - val_loss: 191790.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 191703.0000 - accuracy: 0.0000e+00 - val_loss: 191622.7031 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 191535.4375 - accuracy: 0.0000e+00 - val_loss: 191455.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 191367.8438 - accuracy: 0.0000e+00 - val_loss: 191287.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 191200.3125 - accuracy: 0.0000e+00 - val_loss: 191120.2344 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 191032.9688 - accuracy: 0.0000e+00 - val_loss: 190952.8906 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 190865.7656 - accuracy: 0.0000e+00 - val_loss: 190785.6562 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 190698.5469 - accuracy: 0.0000e+00 - val_loss: 190618.4688 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 190531.3750 - accuracy: 0.0000e+00 - val_loss: 190451.3594 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 190364.3281 - accuracy: 0.0000e+00 - val_loss: 190284.2969 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 190197.3594 - accuracy: 0.0000e+00 - val_loss: 190117.3281 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 190030.4844 - accuracy: 0.0000e+00 - val_loss: 189950.4531 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H0zKKNEBLD5"
      },
      "source": [
        "### Predicting the results of the Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA0yApEmBG1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44497d09-0644-47c8-8435-5079441e588f"
      },
      "source": [
        "# Almacenar valores predichos en una nueva variable\n",
        "y_pred = ann.predict(X_test)\n",
        "\n",
        "# Ajustar que la impresión se haga en 2 decimales\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "#Dar forma vertical a las variables para comparar\n",
        "print(' y_pred vs. y_test')\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " y_pred vs. y_test\n",
            "[[ 18.81 431.23]\n",
            " [ 18.81 460.01]\n",
            " [ 18.81 461.14]\n",
            " ...\n",
            " [ 18.81 473.26]\n",
            " [ 18.81 438.  ]\n",
            " [ 18.81 463.28]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calidad de la estimación\n",
        "Coeficiente de determinación R-squared\n",
        "La calidad de la estimación se puede medir a través del Coeficiente de determinación"
      ],
      "metadata": {
        "id": "KGX4RWa5pxPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Construir el modelo de regresión lineal\n",
        "\n",
        "#Statsmodel ajusta una linea para el conjunto de datos\n",
        "import statsmodels.api as sm\n",
        "\n",
        "#Cte de intercepción\n",
        "X_train_sm=sm.add_constant(X_train)\n",
        "print('Intecepto añadido - '+str(X_train_sm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ3YgdzxhRi0",
        "outputId": "008b1e0f-b96c-4452-f551-a1b8545dc30a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intecepto añadido - [[1.00e+00 8.43e+00 4.07e+01 1.02e+03 8.73e+01]\n",
            " [1.00e+00 2.70e+01 6.10e+01 1.01e+03 5.90e+01]\n",
            " [1.00e+00 2.11e+01 6.31e+01 1.01e+03 9.80e+01]\n",
            " ...\n",
            " [1.00e+00 2.39e+01 5.99e+01 1.01e+03 8.64e+01]\n",
            " [1.00e+00 1.59e+01 4.12e+01 1.01e+03 7.83e+01]\n",
            " [1.00e+00 2.64e+01 4.90e+01 1.01e+03 7.08e+01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajustar la linea de regresión\n",
        "lr=sm.OLS(y_train, X_train_sm).fit()\n",
        "lr.params\n",
        "lr.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "BO2qnl7Njrte",
        "outputId": "ea3cbdad-a0b3-4069-a86c-1dbaf5b674d4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.928\n",
              "Model:                            OLS   Adj. R-squared:                  0.928\n",
              "Method:                 Least Squares   F-statistic:                 1.975e+04\n",
              "Date:                Fri, 20 May 2022   Prob (F-statistic):               0.00\n",
              "Time:                        13:05:04   Log-Likelihood:                -17998.\n",
              "No. Observations:                6123   AIC:                         3.601e+04\n",
              "Df Residuals:                    6118   BIC:                         3.604e+04\n",
              "Df Model:                           4                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const        439.0181     12.347     35.556      0.000     414.813     463.223\n",
              "x1            -1.9636      0.019   -102.166      0.000      -2.001      -1.926\n",
              "x2            -0.2367      0.009    -25.704      0.000      -0.255      -0.219\n",
              "x3             0.0774      0.012      6.457      0.000       0.054       0.101\n",
              "x4            -0.1577      0.005    -30.281      0.000      -0.168      -0.147\n",
              "==============================================================================\n",
              "Omnibus:                      547.032   Durbin-Watson:                   1.990\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2304.747\n",
              "Skew:                          -0.356   Prob(JB):                         0.00\n",
              "Kurtosis:                       5.920   Cond. No.                     2.15e+05\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 2.15e+05. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.928</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.928</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.975e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Fri, 20 May 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>13:05:04</td>     <th>  Log-Likelihood:    </th> <td> -17998.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  6123</td>      <th>  AIC:               </th> <td>3.601e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  6118</td>      <th>  BIC:               </th> <td>3.604e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>  439.0181</td> <td>   12.347</td> <td>   35.556</td> <td> 0.000</td> <td>  414.813</td> <td>  463.223</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>   -1.9636</td> <td>    0.019</td> <td> -102.166</td> <td> 0.000</td> <td>   -2.001</td> <td>   -1.926</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>   -0.2367</td> <td>    0.009</td> <td>  -25.704</td> <td> 0.000</td> <td>   -0.255</td> <td>   -0.219</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>    0.0774</td> <td>    0.012</td> <td>    6.457</td> <td> 0.000</td> <td>    0.054</td> <td>    0.101</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>   -0.1577</td> <td>    0.005</td> <td>  -30.281</td> <td> 0.000</td> <td>   -0.168</td> <td>   -0.147</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>547.032</td> <th>  Durbin-Watson:     </th> <td>   1.990</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2304.747</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.356</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 5.920</td>  <th>  Cond. No.          </th> <td>2.15e+05</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.15e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "R-squared value es 0.928.\n",
        "\n",
        "92.8% de la varianza del peso para el conjunto de datos de prueba puede explicarse por la altura.\n",
        "\n",
        "F es bajo, el ajuste es significativo\n",
        "Los errores estándar suponen que la matriz de covarianza de los errores está correctamente especificada.\n",
        "\n",
        "El número de condición es grande, 2,15e+05. Esto podría indicar que hay fuerte multicolinealidad u otros problemas numéricos."
      ],
      "metadata": {
        "id": "kp-mWFfQoHAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Graficar comparación de resultados\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(y_test, y_pred, c='crimson')\n",
        "plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "\n",
        "p1 = max(max(y_pred), max(y_test))\n",
        "p2 = min(min(y_pred), min(y_test))\n",
        "plt.plot([p1, p2], [p1, p2], 'b-')\n",
        "plt.xlabel('True Values', fontsize=15)\n",
        "plt.ylabel('Predictions', fontsize=15)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "WPnZOV8mP40h",
        "outputId": "efdb54ad-145a-4596-d9af-01d1ae79ba7f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/shape_base.py:65: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ary = asanyarray(ary)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para un conjunto de datos dado, si tenemos una variable dependiente e independiente continua, se puede utilizar un modelo estadístico de regresión lineal simple para predecir la variable dependiente"
      ],
      "metadata": {
        "id": "z-0HGxMq_46d"
      }
    }
  ]
}